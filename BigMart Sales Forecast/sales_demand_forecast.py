# -*- coding: utf-8 -*-
"""Sales Demand Forecast.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JKr3CPYcr04RBYAcHrGjmjJrzW4kUqIe
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.model_selection  import cross_val_score
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor

train = pd.read_csv('Train.csv')
test = pd.read_csv('Test.csv')

train.shape,test.shape

train.head()

test.head()

train.info()

test.info()

"""Visualising missing values using Heatmap"""

sns.heatmap(train.isnull(),yticklabels=False,cbar=False)

sns.heatmap(train.isnull(),yticklabels=False,cbar=False)

train.isnull().sum()/train.shape[0] *100

test.isnull().sum()/test.shape[0] *100

"""**Note:** Percentage of missing values is approx. same for both test and train sets in Item Weight and Outlet Size columns"""

categ_features=[feature for feature in train.columns if train[feature].dtypes == 'O']
categ_features

num_features=[feature for feature in train.columns if train[feature].dtypes != 'O']
num_features

train.describe()

test.describe()

"""# **Data Cleaning**"""

features_with_na = [features for features in train.columns if train[features].isnull().sum()>1]
features_with_na

for feature in features_with_na:
  data=train.copy()
  data[feature]=np.where(data[feature].isnull(),1,0)
  data.groupby(feature)['Item_Outlet_Sales'].median().plot.bar()
  plt.title(feature)
  plt.show()

plt.figure(figsize=(8,5))
sns.boxplot('Item_Weight',data=train)

plt.figure(figsize=(8,5))
sns.boxplot('Item_Weight',data=test)

train['Item_Weight']= train['Item_Weight'].fillna(train['Item_Weight'].mean())
test['Item_Weight']= test['Item_Weight'].fillna(test['Item_Weight'].mean())

print(train['Outlet_Size'].value_counts())
print(test['Outlet_Size'].value_counts())

train['Outlet_Size']= train['Outlet_Size'].fillna(train['Outlet_Size'].mode()[0])
test['Outlet_Size']= test['Outlet_Size'].fillna(test['Outlet_Size'].mode()[0])

sns.heatmap(train.isnull(),yticklabels=False,cbar=False)

sns.heatmap(test.isnull(),yticklabels=False,cbar=False)

"""We can observe from above heatmaps that the missing values have been imputed

**Exploratory Data Analysis**
"""

train['Item_Fat_Content'].value_counts()

test['Item_Fat_Content'].value_counts()

"""We see there are some irregularities in the column and they need fixing"""

train['Item_Fat_Content'].replace(['low fat','LF','reg'],['Low Fat','Low Fat','Regular'],inplace = True)
test['Item_Fat_Content'].replace(['low fat','LF','reg'],['Low Fat','Low Fat','Regular'],inplace = True)

train['Item_Fat_Content']= train['Item_Fat_Content'].astype(str)
test['Item_Fat_Content']= test['Item_Fat_Content'].astype(str)

train['Years_Established'] = train['Outlet_Establishment_Year'].apply(lambda x: 2021 - x) 
test['Years_Established'] = test['Outlet_Establishment_Year'].apply(lambda x: 2021 - x)

train.head()

test.head()

"""**Univariate Analysis**"""

for feature in categ_features:
  if feature=='Item_Identifier':
    pass
  else:
    sns.countplot(feature,data=train,palette='ocean')
    plt.show()

"""**Observati0ns from categ variables:**

Item_Fat_Content - Most items sold are low fat.

Item_Type - Item types that are distictly popular are fruits and vegetables and snack foods.

Outlet_Identifier - Sold items are ditributed evenly among outlets excluding OUT010 and OUT019 that are significanly lower.

Outlet_Size - Bigmart outlets are mostly medium sized in our data.

Outlet_Location_Type - The most common type is Tier3.

Outlet_Type - By a wide margin the mode outlet type is Supermarket Type1.

Checking the distribution of numerical variables
"""

for feature in num_features:
  sns.distplot(train[feature], kde=False)
  plt.show()

"""**Bivariate Analysis**"""

for feature in categ_features:
  if feature=='Item_Identifier':
    pass
  else:
    sns.barplot(feature,'Item_Outlet_Sales',data=train,palette='mako')
    plt.show()

for feature in num_features:
  sns.scatterplot(train[feature],train['Item_Outlet_Sales'])
  plt.show()

"""Item_Visibility has a minimum value of zero. This makes no practical sense because when a product is being sold in a store, the visibility cannot be 0.Lets consider it like missing information and impute it with mean visibility of that product"""

train['Item_Visibility']=train['Item_Visibility'].replace(0,train['Item_Visibility'].mean())

plt.figure(figsize=(8,5))
plt.scatter(y='Item_Visibility',x='Item_Outlet_Sales',data=train)
plt.xlabel('Item Outlet Sales')
plt.ylabel('Item Visibility')



"""We can see visibility of a product doesn't actually lead to it's sales much.

**Observations from numerical varuables:**

Outlet_Age - The most common outlets are 35 years old.

Item_Weight - The data is very spreaded, no specific pattern.

Item_Visibility - Appears to be spreaded as well but some concentration around the (0,0) indicate small visibility items are not selling well is some cases.

Item_MRP - Items with higher MRP tend to sell better in most cases.

**Multivariate Analysis**
"""

sns.barplot('Outlet_Location_Type','Item_Outlet_Sales',hue='Outlet_Type',data=train,palette='magma')
plt.legend()

plt.figure(figsize=(25,5))
sns.barplot('Item_Type','Item_Outlet_Sales',hue='Item_Fat_Content',data=train,palette='mako')
plt.legend()

"""**Observations:**

The difference in item types by sales is very small.

Outlet 27 is the most profitable and there is a big diffrence between each specific outlet sales.

Suprisingly supermarket type 3 is the most profitable and not type 1.

Medium and high outlet sizes are pretty much even in sales.

Tier 2 and 3 are almost even being the highest in sales (2 is slightly larger).

The Tier-3 location type has all types of Outlet type and has high sales margin.
"""

sns.pairplot(train)

corr=train.corr()
#plt.figure(figsize=(5,5))
sns.heatmap(train.corr(),annot=True,cmap='rocket')

"""We can observe that 'Item_Mrp' has a strong correlation with 'Item_outlet_Sales'"""

#lable encoding

le = LabelEncoder()
Label = ['Item_Fat_Content','Outlet_Size','Outlet_Location_Type']

for i in Label:
    train[i] = le.fit_transform(train[i])
    test[i] = le.fit_transform(test[i])
    
train.head()

"""There are some columns that needs to be dropped as they don't seem helping our analysis"""

train = train.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year'],axis=1)
test= test.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year'],axis=1)

#one hot encoding
cols = ['Item_Type','Outlet_Type']
# Apply one-hot encoder
OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
tr_oh = pd.DataFrame(OH_encoder.fit_transform(train[cols])).astype('int64')
ts_oh = pd.DataFrame(OH_encoder.fit_transform(test[cols])).astype('int64')

#get feature columns
tr_oh.columns = OH_encoder.get_feature_names(cols)
ts_oh.columns = OH_encoder.get_feature_names(cols)

# One-hot encoding removed index; put it back
tr_oh.index = train.index
ts_oh.index = test.index

# Add one-hot encoded columns to our main df new name: tr_fe, te_fe (means feature engeenired) 
train = pd.concat([train, tr_oh], axis=1)
test = pd.concat([test, ts_oh], axis=1)

"""We also need to drop the one hot encoded columns"""

train = train.drop(cols,axis=1)
test= test.drop(cols,axis=1)

train.head()

train.shape

"""**Data Transformation**

Log Normalisation to remove skewness
"""

for column in train.columns:
  train[column] += 1
  train[column] = np.log(train[column])


for column in test.columns:
  test[column] += 1
  test[column] = np.log(test[column])

train.head()

"""**Feature Selection**

Correlation
"""

X = train.drop(["Item_Outlet_Sales"],axis=1)
y = train["Item_Outlet_Sales"]

corr=X.corr()
plt.figure(figsize=(20,20))
sns.heatmap(X.corr(),annot=True,cmap='rocket')

threshold=0.8

# find and remove correlated features
def correlation(X, threshold):
    col_corr = set()  # Set of all the names of correlated columns
    corr_matrix = X.corr()
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value
                colname = corr_matrix.columns[i]  # getting the name of column
                col_corr.add(colname)
    return col_corr

correlation(X,threshold)

X.drop(correlation(X,threshold),axis=1,inplace=True)

X.shape

"""Standardisation"""

scalar = StandardScaler()
X = scalar.fit_transform(X)
X_te = scalar.fit_transform(test)

X

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3)

"""**Finding the best model**"""

from sklearn.model_selection import GridSearchCV
from sklearn.metrics  import r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

RandomForestReg = RandomForestRegressor()
linearReg = LinearRegression()

param_grid_Random_forest_Tree = {
                                "n_estimators": [10,20,30],
                                "max_features": ["auto", "sqrt", "log2"],
                                "min_samples_split": [2,4,8],
                                "bootstrap": [True, False]}

grid = GridSearchCV(RandomForestReg, param_grid_Random_forest_Tree, verbose=3, cv=5)
# finding the best parameters
grid.fit(X_train, y_train)

n_estimators = grid.best_params_['n_estimators']
max_features = grid.best_params_['max_features']
min_samples_split = grid.best_params_['min_samples_split']
bootstrap = grid.best_params_['bootstrap']

RandomForestReg = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features,
                                                         min_samples_split=min_samples_split, bootstrap=bootstrap)

RandomForestReg.fit(X_train, y_train)

# create best model for XGBoost
prediction_randomForestReg = RandomForestReg.predict(X_test)  # Predictions using the randomForestReg Model
prediction_randomForestReg_error = r2_score(y_test,prediction_randomForestReg)

prediction_randomForestReg_error

param_grid_linearReg = {
                'fit_intercept': [True, False], 'normalize': [True, False], 'copy_X': [True, False]}

grid= GridSearchCV(linearReg,param_grid_linearReg, verbose=3,cv=5)

grid.fit(X_train, y_train)

fit_intercept = grid.best_params_['fit_intercept']
normalize = grid.best_params_['normalize']
copy_X = grid.best_params_['copy_X']

linReg = LinearRegression(fit_intercept=fit_intercept,normalize=normalize,copy_X=copy_X)
# training the mew model
linReg.fit(X_train, y_train)

prediction_LinearReg=linReg.predict(X_test)

linearReg_error = r2_score(y_test,prediction_LinearReg)

linearReg_error

r2_score

from sklearn.linear_model import Lasso

lasso = Lasso(alpha = 0.05)

lasso.fit(X_train,y_train)

#predict
prediction_lasso = lasso.predict(X_test)

grid= GridSearchCV(lasso,param_grid_linearReg, verbose=3,cv=5)
grid.fit(X_train, y_train)

lasso_error = r2_score(y_test,prediction_lasso)

lasso_error